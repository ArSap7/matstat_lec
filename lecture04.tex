%!TEX TS-program = xelatex
\documentclass[12pt, a4paper, oneside]{article}

% Можно вставить разную преамбулу
\input{preamble}

\title{
\begin{center} 
\includegraphics[width=0.99\textwidth]{logo.png}
\end{center}

Посиделка 4: мощь средних}
\date{ } %\today}

% Если делаешь конспект, вписывай своё имя прямо сюда!
\author{Ульянкин Ппилиф}

\begin{document} % Конец преамбулы, начало файла

\maketitle

\epigraph{Цитата про средние и асимптотику}{\textit{Её автор}}


В этой лекции мы поговорим про ... Хорошо было бы, если бы читатель знал что такое доверительный интервал и хотябы раз в жизни проверял гипотезы. 

\section{Схема статистики и подходы к ней}

- Статистика средних и лонг-рана
- Статистика максимального правдоподобия 
- Байесовская статистика
- Информационные критерии и тп 


Сегодня мы поговорим про статистику средних. Искать точечную оценку будем с помощью метода моментов, который основан на закона больших чисел (ЗБЧ). Искать распределение оценки будем с помощью центральной предельной теоремы (ЦПТ).

\section{Метод моментов и ЗБЧ}

Пусть случайные величины $X_{1}, \ldots, X_{n}$ независимы и одинаково распределены. Закон больших чисел говорит нам, что среднее выборочное $ \bar{X} $ является хорошей оценкой для математического ожидания $ \E(X_{i}) $.

\begin{theorem}{\textbf{Закон Больших Чисел (Пафнутий Львович Чебышёв)}}

Пусть $X_1, \ldots, X_n$ попарно независимые и одинаково распределённые случайные величины с конечным вторым моментом, $0 < E(X_i^2) < \infty$, тогда:

$$
\bar{X}_{n} = \frac{X_1 + \ldots + X_n}{n} \stackrel{p}{\longrightarrow} E(X_1)
$$
\end{theorem}

На практике это означает, что при больших $n$ эти величины равны:

\[
\bar{X}_{n}\approx \E(X_{i}).
\]

На этой нехитрой идее и построен метод моментов. Как конкретно используется идея, понятно из следующих двух примеров.

\begin{problem}{(киндеры)}
Максим любит киндеры и собирает коллекцию жирОфов. Для этого он покупает шоколадки. Пусть вероятность $p$ --- вероятность того, что в киндере лежит жирОф. Максим считает сколько яиц надо купить, чтобы у него появился очередной жирОф. Каждый раз Макс записывает номер попытки, с которой у него появилась правильная игрушка. Обозначим эти величины $X_{1}, \ldots, X_{n} $. Постройте оценку неизвестного параметра $ p $ с помощью метода моментов.
\end{problem}

\begin{sol}
\indef{Эксперимент} состоит в том, что Максим ест шоколад и собирает \indef{выборку} из своих попыток раздобыть нужную игрушку. \indef{Вопрос} Макса заключается в том, насколько часто встречаются жирОфы. \indef{Модель} Макса, в которую он верит заключается в том, что величины $ X_{i} $ имеют геометрическое распределение, поэтому $ \E(X_{i})=\frac{1}{p} $. Принцип метода моментов гласит:
	\[ \bar{X}_{n}\approx \frac{1}{p}\]
	Выражаем неизвестный параметр $ p $:
	\[ p\approx \frac{1}{\bar{X}_{n}} \]
	Это и есть нужная нам оценка:
	\[ \hat{p}_{MM} = \frac{1}{\bar{X}_{n}} \]
\end{sol}


\begin{problem}{(Шарик и фарш)}
Продавщица Глафира отдаёт псу Шарику в конце каждого дня нерасфасованные остатки мясного фарша. Фарш фасуется упаковками по $a$ грамм, поэтому нерасфасованный остаток в $i$-ый день, $X_i$, случаен и равномерно распределен на отрезке $[0;a]$. Пёс Шарик хорошо помнит все $X_1$, \ldots, $X_n$. Помогите псу Шарику найти оценку $a$ методом моментов.
\end{problem}

\begin{sol}
\indef{Эксперимент} состоит в том, что Шарик каждый день ест фарш и собирает \indef{выборку.} \indef{Вопрос} Шарика заключается в том, сколько максимально фарша он может получить. \indef{Модель} Шарика, в которую он верит --- выборка приходит из равномерно распределения. В рамках этой веры мы пробуем решить задачу.

В данном случае $ \E(X_{i})=\frac{a}{2} $ и, следовательно
\[ \bar{X}_{n}\approx \frac{a}{2}. \]
Выражаем $a$
\[ a \approx 2 \cdot \bar{X}_{n}, \]
это и есть нужная нам оценка:
\[ \hat{a}^{MM}= 2 \cdot \bar{X}_{n}. \]
\end{sol}

\begin{definition} 
Пусть $ X_{i} $ одинаково распределены и независимы, а $ \E(X_{i}) $ зависит от неизвестного параметра $ \theta $, скажем $ \E(X_{i}) = f(\theta) $. Тогда \indef{оценкой метода моментов} называется случайная величина:
\[ \hat{\theta}_{MM} = f^{-1}(\bar{X}_{n}) \]
\end{definition} 

Конечно, иногда бывают ситуации, когда математическое ожидание $\E(X_{i})$ не зависит от $\theta$. Например, если $X_{i}$ равномерны на $[-\theta; \theta]$, то математическое ожидание $\E(X_{i})=0$. Что делать в такой ситуации? 

Неспроста же наш метод называется методом моментов\ldots  Напомним, что $k$-ым моментом случайной величины $X_{i}$ называется математическое ожидание $\E(X_{i}^{k})$ \ldots 

Итак, если условия $\bar{X}_{n}\approx \E(X_{i})$ связанного с первым моментом не хватило, то на помощь придет второй момент случайной величины. В силу того же закона больших чисел:

\[\overline{X^2}_n = \frac{X_{1}^{2} + \ldots + X_{n}^{2}}{n} \approx \E(X_{i}^{2})\]

\begin{problem}{(равномерное)}
Величины $ X_{i} $ независимы и равномерны на $ [-\theta;\theta] $. Постройте оценку неизвестного параметра $ \theta $ с помощью метода моментов.
\end{problem}

\begin{sol}
Убеждаемся, что $\E(X_{i})=0$:

\[  \E(X_{i}) = \int _{-\theta}^{\theta} x \cdot \frac{1}{2\theta} \dx{x} = \left. \frac{x^2}{4 \theta} \right|_{-\theta}^{\theta} = \left( \frac{\theta^2 - (-\theta)^2 }{4 \theta}  \right) =  \frac{\theta^{2} - \theta^{2}}{4 \theta} = 0  \]

Находим $ \E(X_{i}^{2}) $:

\[  \E(X_{i}^{2}) = \int _{-\theta}^{\theta} x^{2} \cdot \frac{1}{2\theta}  \dx{x} = \left. \frac{x^3}{6 \theta} \right|_{-\theta}^{\theta} = \left( \frac{\theta^3 - (-\theta)^3 }{6\theta}  \right) = \frac{2 \theta^{3}}{6\theta}  = \frac{\theta^{2}}{3}  \]

Согласно принципу метода моментов

\[ \frac{\sum X_{i}^{2}}{n} \approx \frac{\theta^{2}}{3}.\]

Выражаем $ \theta $

\[ \theta\approx \sqrt{3\frac{\sum X_{i}^{2}}{n} }.\]

Это и есть нужная нам оценка

\[ \hat{\theta}_{MM}= \sqrt{3\frac{\sum X_{i}^{2}}{n} } = \sqrt{3 \overline{X^2 } }.\]
\end{sol}

Если не хватит и второго момента, тогда воспользуемся третьим и т.д. Для произвольного $k$ мы имеем

\[ \frac{X_{1}^{k} + \ldots + X_{n}^{k}}{n} \approx \E(X_{i}^{k})\]

В большинстве случаев хватает именного первого момента. Последующие моменты нужны чаще всего при оценке нескольких параметров.

\todo[inline]{Сделать тут пример с двумя параметрами}

\section{Метод моментов и ЦПТ}

Точечная оценка --- это хорошо. К сожалению, чаще всего нам этого мало. Всегда хочется понимать, насколько оценка получилась точной. В рамках статистики средних, нам в этом помогают доверительные интервалы, то есть промежутки, которые накрывают истинное значение параметра с высокой вероятностью. Построить доверительные интервалы нам помогает ЦПТ.

\begin{theorem}{\textbf{Центральная Предельная Теорема (Прокопий Петрович Ляпунов)}}

Пусть $X_1, \ldots, X_n$ попарно независимые и одинаково распределённые случайные величины с конечным вторым моментом, $0 < E(X_i^2) < \infty$, тогда при $n \to \infty$ имеет место сходимость по распределению: 

$$
\bar{X}_n \stackrel{d}{\longrightarrow} N \left(\E(X_i), \frac{\Var(X_i)}{n} \right)
$$

Этот же факт можно переписать немного иначе:

\begin{equation*}
\begin{aligned} 
\sqrt{n} \cdot [\bar{x} - \E(X_i)]  &\stackrel{d}{\longrightarrow} N \left(0, \Var(X_i)\right)\\
\sqrt{n} \cdot \frac{\bar{x} - \E(X_i)}{\sqrt{\Var(X_i)}}  &\stackrel{d}{\longrightarrow} N \left(0, 1\right).
\end{aligned} 
\end{equation*} 
\end{theorem}

Если говорить простым языком, то при определённых условиях сумма достаточно большого числа случайных величин имеет распределение близкое к нормальному. \indef{Главное, чтобы случайные величины были похожи и не было такого, что одна резко выделяется на фоне остальных.}

Давайте посмотрим, как будет вести себя среднее в примере с Шариком и Глафирой.

\begin{problem}{(Шарик и фарш)}
Величины $X_1$, \ldots, $X_n \sim \iid U[0;a]$. Найдите для $a$ оценку методом моментов и постройте для неё доверительный интервал. У Шарика есть гипотеза, что вес упаковки не может превышать $100$ грамм. Формализуйте эту гипотезу и опишите процедуру её проверки. 
\end{problem}

\begin{sol}
Мы нашли оценку метода моментов, оказалось что 
\[ \hat{a} = 2 \cdot \bar{X}_{n}. \]

В данном случае $\Var(X_i) = \frac{a^2}{12}.$ Получается, что $\Var(\bar x) = \frac{a^2}{12 \cdot n}.$ Воспользовавшись ЦПТ мы можем выписать асимптотическое распределение среднего 

\[\bar{X}_n \overset{\text{\textit{asy}}}{\sim} \mN \left(\frac{a}{2}, \frac{a^2}{12 \cdot n} \right).\] 

По свойствам нормального распределения получаем распределение для оценки неизвестного параметра

\[\hat{a}= 2 \bar{X}_{n} \overset{\text{\textit{asy}}}{\sim} \mN \left(a, \frac{a^2}{3 \cdot n} \right).\] 

Немного перепишем 

\[ T = \frac{ 2 \bar{X}_{n} - a}{\sqrt{\frac{a^2}{3 \cdot n}} } \overset{\text{\textit{asy}}}{\sim} \mN \left(0, 1 \right).\] 

Построим доверительный интервал для $a$, зажмём случайную величину $T$ между её квантилями так, чтобы 

$$
\PP \left( z_{1 - \frac{\alpha}{2}} \le \frac{ 2 \bar{X}_{n} - a}{\sqrt{\frac{a^2}{3 \cdot n}} } \le z_{1 - \frac{\alpha}{2}} \right) = 1 - \alpha.
$$

Такой интервал для случайной величины $T$ называется \indef{предиктивным интервалом.} Его границы фиксированы, а в центре находится случайная величина. Давайте разрешим неравенство относительно $a$. Тогда мы получим, что

$$
\PP\left(2 \bar{X}_{n}  - z_{1 - \frac{\alpha}{2}} \cdot \sqrt{\frac{a^2}{3 \cdot n}}  \le a \le 2 \bar{X}_{n}  + z_{1 - \frac{\alpha}{2}} \cdot \sqrt{\frac{a^2}{3 \cdot n}} \right) = 1 - \alpha.
$$

Таким образом $a$ оказалась по центру. Если мы оценим по нашей выборке дисперсию, тогда мы сможем получить диапазон в границах которого лежит неизвестный параметр $a$ с вероятностью $1 - \alpha$

$$
\PP\left(2 \bar{X}_{n}  - z_{1 - \frac{\alpha}{2}} \cdot \sqrt{\frac{\bar{X}_{n}^2}{3 \cdot n}}  \le a \le 2 \bar{X}_{n}  + z_{1 - \frac{\alpha}{2}} \cdot \sqrt{\frac{\bar{X}_{n}^2}{3 \cdot n}} \right) = 1 - \alpha.
$$

Такой интервал называется \indef{доверительным интервалом.} Его границы --- случайные величины, а в середине стоит неизвестная константа, которую доверительный интервал накрывает с вероятностью $1 - \alpha$. 

Пока не очень понятно, почему мы заменили параметр $a$ в дисперсии на его оценку. Чуть ниже мы формально докажем, что такая замена никогда не портит асимптотику. 

Займёмся гипотезой шарика. Ему кажется, что вес упаковки не превышает $100$ грамм. Давайте для начала \indef{проверим гипотезу о том, что вес упаковки не отличается от $100$ грамм}

\begin{equation*} 
\begin{aligned} 
& H_0: a = 100 \\
& H_a: a \ne 100.
\end{aligned} 
\end{equation*} 

Оценка $\hat a$ --- случайная величина. Расстояние $\hat a - 100$ тоже случайная величина. Если наша гипотеза верна, $\hat a - 100$ должно быть близко к нулю. 

\todo[inline]{Дописать оба варианта проверки гипотезы, сделать отсылки к 1 лекции.}
\end{enumerate}

\end{sol}


\section{Дельта-метод}

Кроме Глафиры у нас была задача про Макса и Жирафов. Там у нас получилась оценка $\hat p = \frac{1}{\bar x}.$ Здесь мы не можем воспользоваться ЦПТ для строительства доверительного интервала. Зато мы можем воспользоваться её обобщением, дельта-методом. 

Нормальное распределение возникает, если суммируется большое количество независимых одинаково распределенных случайных величин. Однако оно возникает и в других ситуациях! Дельта-метод основан на том факте, что даже нелинейная функция от нормально распределенной случайной величины  иногда имеет распределение близкое к нормальному.

\begin{theorem}{\textbf{Центральная Предельная Теорема (Прокопий Петрович Ляпунов)}}

Пусть $X_1, \ldots, X_n$ попарно независимые и одинаково распределённые случайные величины с конечным вторым моментом, $0 < E(X_i^2) < \infty$, а $g(t)$ дифференцируемая функция. Пусть $\E(X_i) = \mu, \Var(X_i) = \sigma^2,$ тогда при $n \to \infty$ имеет место сходимость по распределению: 

\[
\sqrt{n} (g(\bar X_n) - g(\mu)) \stackrel{d}{\longrightarrow} \mN(0, \frac{\sigma^2}{n} (g'(\mu))^2 ).
\]

Иными словами говоря, 

\[
g(\bar{X}_n) \overset{\text{\textit{asy}}}{\sim} \mN \left(g(\mu), \frac{\sigma^2}{n} \cdot (g'(\mu))^2 \right).\] 
\end{theorem}

Попробуем применить его на практике. 

\begin{problem}{(Равномерное)}
Пусть случайные величины $X_1, \ldots, X_{100} \iid U[2;8]$. Как будут распределены $\bar{x}$ и $\frac{1}{\bar{x}}$? 
\end{problem} 

\begin{sol}
С $\bar{x}$ всё будет просто. Воспользуемся ЦПТ, по ней 

$$
\bar{x}\sim \mN \left( \E(X_i), \frac{\Var(X_i)}{n} \right).
$$

Для равномерного распределения $\E(X_i) = \frac{2 + 8}{2} = 5$, $\Var(X_i) = \frac{(8-2)^2}{12} = 3$.

Получается, что среднее посчитанное по сотне наблюдений будет иметь распределение 

$$
\bar{x}_{100} \sim \mN \left( 5, \frac{3}{100} \right).
$$

Для поиска распределения $\frac{1}{\bar{x}}$ воспользуемся дельта-методом: 

$$
g(t) = \frac{1}{t} \qquad g'(t) = -\frac{1}{t^2} \qquad g(\mu) = \frac{1}{5} \qquad g'(\mu) = - \frac{1}{25}.
$$

Остаётся только подставить  найденные значения в формулу и получить, что 

$$
\frac{1}{\bar{x}_{100}} \sim \mN \left( \frac{1}{5}, \frac{3}{100} \cdot \left(-\frac{1}{25} \right)^2\right).
$$
\end{sol}









\section*{Откуда берётся дельта-метод}

Если функция $g(t)$ дифференцируема, то в окрестности точки $\mu$ функция $g(t)$ похожа на прямую, то есть 

$$
g(t) \approx g(\mu) + g'(\mu) \cdot (t - \mu).
$$

Об этом нам говорит математический анализ, в частности, разложение в ряд Тэйлора. 

Линейное преобразование нормально распределенной случайной величины оставляет её нормально распределенной, если угловой коэффициент отличен от нуля, т.е. 

$$
g'(\mu) \neq 0.
$$ 

Если $X \sim \mN(\mu, \sigma^2)$ и  дисперсия $X$ мала, то $X$ практически всегда попадает в небольшую окрестность $\mu$, а в ней $f$ похожа на линейную функцию и 

$$
g(X) \approx N(\mu, \sigma^2 (g'(\mu))^2.
$$ 

\indef{Получаем практическую версию дельта-метода.} Если: 

\begin{itemize}
	\item  $g(t)$ --- дифференциируема;
	\item  $g'(\mu) \neq 0$;
	\item $X \sim \mN(\mu,\sigma^2)$;
	\item дисперсия $\sigma^2$ мала;
\end{itemize} 

тогда 

$$
g(X) \sim \mN(g(\mu),\sigma^2 (g'(\mu))^2).
$$


ЗБЧ позволяет использовать средние в качестве оценок для различных параметров. ЦПТ подсказывает как среднее будет распределено. Однако на практике часто встречаются ситуации, когда оценка параметра --- это функция от среднего.  \indef{Дельта-метод ---} позволяет в такой ситуации понять как будет распределена оценка. Полученное распределение можно использовать для строительства доверительного интервала. 


\section*{Дельта-метод на практике}



\begin{problem}{(Пуассона)}
Пусть $X_1, \ldots, X_n \iid \Pois(\lambda)$.   С помощью дельта-метода найдите как распределена оценка вероятности $\PP(X_i = 0)$.
\end{problem} 

\begin{sol}
В качестве оценки для $\lambda$ будем использовать оценку метода моментов, $\bar{x}$.  Среднее по ЦПТ имеет асимптотически нормальное распределение

$$
\bar{x}\sim \mN \left(\lambda, \frac{\lambda}{n} \right).
$$

Вероятность того, что $X_i = k$ считается по формуле 

$$
\PP(X_i = k) = \frac{\lambda^k}{k!} \cdot e^{-\lambda},
$$ 

в частности 

$$
\PP(X_i = 0) = e^{-\lambda}.
$$

Для оценки последней, $e^{-\bar{x}}$ нам нужно найти распределение. Воспользуемся  дельта-методом:

$$
g(t) = e^{-t} \qquad g'(t) = -e^{-t}
$$

Подставим значения в формулу и получим, что 

$$
e^{-\bar{x}} \sim \mN \left( e^{-\lambda},  \frac{\lambda}{n} \cdot e^{-2 \cdot \lambda}  \right).
$$

В дисперсию можем подставить вместо $\lambda$ её оценку

$$
e^{-\bar{x}} \sim \mN \left( e^{-\lambda},  \frac{\bar{x}}{n} \cdot e^{-2 \cdot \bar{x}}  \right).
$$

Такое распределение мы сможем использовать для строительства доверительных интервалов и дальнейшего анализа.
\end{sol}


\section*{Дельта-метод в теории}

Естественно, строгая формулировка идеи <<дисперсия $\sigma^2$ мала>> использует понятие предела и последовательностей случайных величин.

Если:  $g(t)$ --- дифференцируема, $g'(\mu)\neq 0$, и последовательность случайных величин $X_1, X_2, \ldots, X_n, \ldots $ удовлетворяет условию:

\[
\sqrt{n} (X_n - \mu) \overset{d}{\to}  \mN(0,\sigma^2),
\]

тогда последовательность $g(X_n)$ удовлетворяет условию:

\[
\sqrt{n} (g(X_n) - g(\mu)) \overset{d}{\to} \mN(0,\sigma^2 (g'(\mu))^2 )
\]




\subsection{Одномерный} 

\subsection{Многомерный} 

\section{Обобщённый метод моментов} 

\section{Средние не панацея}

Тут о важности предпосылок и тп на примере задачи про Киллера


\section*{Почиташки} 

\todo[inline]{Сюда список литературы к лекции}


\end{document}